{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from typing import List, Tuple, Dict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(\"aosp_acs.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cursor_to_dataframe(cursor):\n",
    "    with warnings.catch_warnings():\n",
    "        # TODO: pandas 2.1.0 has a FutureWarning for concatenating DataFrames with Null entries\n",
    "        warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "        columns = [desc[0] for desc in (cursor.description)]\n",
    "        df_records = pd.DataFrame(columns=columns)\n",
    "        for row in cursor:\n",
    "            df_temp = pd.DataFrame([row], columns=columns)\n",
    "            if df_temp.empty:\n",
    "                continue\n",
    "            df_records = pd.concat([df_records, df_temp])\n",
    "    return df_records.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acs_in_a_project(project_name) -> pd.DataFrame:\n",
    "    cursor = db.execute(\"SELECT count(id) as ac_count,path,ac,loc FROM ac_reports WHERE path IN (SELECT path FROM files WHERE files.project_name = ?) GROUP BY path,ac\",(project_name,))\n",
    "    return cursor_to_dataframe(cursor)\n",
    "\n",
    "def ck_in_a_project(project_name) -> pd.DataFrame:\n",
    "    cursor = db.execute(\"SELECT * from classes WHERE file_path IN (SELECT path FROM files WHERE files.project_name = ?)\", (project_name,))\n",
    "    df = cursor_to_dataframe(cursor)\n",
    "    NUMERIC_FIELDS = ['cbo', 'cboModified', 'fanin',\n",
    "       'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom_normalized', 'tcc',\n",
    "       'lcc', 'totalMethodsQty', 'staticMethodsQty', 'publicMethodsQty',\n",
    "       'privateMethodsQty', 'protectedMethodsQty', 'defaultMethodsQty',\n",
    "       'visibleMethodsQty', 'abstractMethodsQty', 'finalMethodsQty',\n",
    "       'synchronizedMethodsQty', 'totalFieldsQty', 'staticFieldsQty',\n",
    "       'publicFieldsQty', 'privateFieldsQty', 'protectedFieldsQty',\n",
    "       'defaultFieldsQty', 'finalFieldsQty', 'synchronizedFieldsQty', 'nosi',\n",
    "       'loc', 'returnQty', 'loopQty', 'comparisonsQty', 'tryCatchQty',\n",
    "       'parenthesizedExpsQty', 'stringLiteralsQty', 'numbersQty',\n",
    "       'assignmentsQty', 'mathOperationsQty', 'variablesQty',\n",
    "       'maxNestedBlocksQty', 'anonymousClassesQty', 'innerClassesQty',\n",
    "       'lambdasQty', 'uniqueWordsQty', 'modifiers', 'logStatementsQty']\n",
    "    for field in NUMERIC_FIELDS:\n",
    "        df[field] = df[field].astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"Prevalence report of AC in a project\"\"\"\n",
    "def report_types_of_aocs(project_name) -> dict:\n",
    "    sql = f\"SELECT ac, count(id) as qty FROM ac_reports WHERE project_name LIKE '{project_name}' GROUP BY ac ORDER BY qty DESC\"\n",
    "    cursor = db.execute(sql)\n",
    "    return cursor_to_dataframe(cursor)\n",
    "\n",
    "def files_in_a_project(project_name) -> pd.DataFrame:\n",
    "    cursor = db.execute(\"SELECT * FROM files WHERE project_name = ?\", (project_name,))\n",
    "    return cursor_to_dataframe(cursor)\n",
    "\n",
    "def loc_of_file(file_name) -> int:\n",
    "    cursor = db.execute(\"SELECT loc FROM files WHERE path = ?\", (file_name,))\n",
    "    return int(next(cursor)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of core apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db.execute(\"SELECT * FROM files WHERE path LIKE '/AOSP/packages/apps%';\")\n",
    "apps_set = set()\n",
    "for path,loc, project_name in cursor:\n",
    "    apps_set.add(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_data :Dict[str, Dict[str, pd.DataFrame]] = {}\n",
    "for project in apps_set:\n",
    "    apps_data[project] = {\n",
    "        \"ck\": ck_in_a_project(project),\n",
    "        \"acs\": acs_in_a_project(project),\n",
    "        \"files\": files_in_a_project(project)\n",
    "    }\n",
    "\n",
    "print(\"Projects processed: \", len(apps_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVG, median, percentiles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ck(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    output = pd.DataFrame()\n",
    "    for col in df.columns:\n",
    "        nonnull = df[col].dropna()\n",
    "        try:\n",
    "            output[f\"{col}__mean\"] = nonnull.mean(skipna=True)\n",
    "            output[f\"{col}__median\"] = nonnull.median(skipna=True)\n",
    "            output[f\"{col}__mode\"] = nonnull.mode(dropna=True)\n",
    "            output[f\"{col}__90_perc\"] = nonnull.quantile(.90 )\n",
    "        except Exception as e:\n",
    "            print(\"Exception: \", e)\n",
    "            print(f\"Skipping column {col} of type {nonnull.dtype}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_data[project_name][\"acs\"].loc[apps_data[project_name][\"acs\"][\"ac\"] == \"Logic as Control Flow\"][\"ac_count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countacs(project_name: str) -> pd.DataFrame:\n",
    "    loc_sum = apps_data[project_name][\"files\"][\"loc\"].sum()\n",
    "    ac_count = apps_data[project_name][\"acs\"][\"ac_count\"].sum()\n",
    "    loc_by_acs = loc_sum/ac_count if ac_count > 0 else -1\n",
    "    return pd.DataFrame([(loc_sum, ac_count, loc_by_acs)], columns=[\"loc_sum\", \"ac_count\", \"loc_by_acs\"])\n",
    "\n",
    "\n",
    "\n",
    "df_apps_ac: pd.DataFrame = pd.DataFrame()\n",
    "for idx, project_name in enumerate(apps_set):\n",
    "    apps_ac_map = countacs(project_name)\n",
    "    apps_ac_map = apps_ac_map.assign(project_name=[project_name])\n",
    "    df_apps_ac = pd.concat([df_apps_ac, apps_ac_map])\n",
    "df_apps_ac = df_apps_ac.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apps_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc_by_acs = df_apps_ac.sort_values(\"loc_by_acs\", ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ax.bar(df_loc_by_acs[\"project_name\"], df_loc_by_acs[\"loc_by_acs\"], 0.9)\n",
    "ax.figure.set_figwidth(12)\n",
    "ax.figure.set_figheight(5)\n",
    "ax.yaxis.set_label_text(\"Lines of code per AC\")\n",
    "ax.xaxis.set_label_text(\"Project Name\")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ac_report_bar(project_name):\n",
    "    df_report = report_types_of_aocs(project_name)\n",
    "    df_report = df_report.assign(perc=(df_report[\"qty\"] / df_report[\"qty\"].sum()).astype(float).round(2))\n",
    "    df_report = df_report.assign(label=df_report[\"ac\"] + \" \" + df_report[\"perc\"].astype(str))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.figure.set_figwidth(12)\n",
    "    ax.figure.set_figheight(5)\n",
    "    wedges, _ = ax.pie(df_report[\"perc\"], wedgeprops=dict(width=0.5), startangle=0)\n",
    "\n",
    "    # https://matplotlib.org/stable/gallery/pie_and_polar_charts/pie_and_donut_labels.html\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    kw = dict(arrowprops=dict(arrowstyle=\"-\"),\n",
    "          bbox=bbox_props, zorder=0, va=\"center\")\n",
    "\n",
    "    for i, p in enumerate(wedges):\n",
    "        Epsilon = .00001\n",
    "        ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "        if ang == 180:\n",
    "            ang = 179\n",
    "        y = np.sin(np.deg2rad(ang))\n",
    "        x = np.cos(np.deg2rad(ang))\n",
    "        horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "        connectionstyle = f\"angle,angleA=0,angleB={ang}\"\n",
    "        kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
    "        ax.annotate(df_report[\"label\"][i], xy=(x + Epsilon, y + Epsilon), xytext=(1.35*np.sign(x), 1.4*y),\n",
    "                    horizontalalignment=horizontalalignment, **kw)\n",
    "    ax.set_title(f\"Prevalence of {project_name}\")\n",
    "    plt.savefig(f\"imgs/prevalence_{project_name.replace('/', '_')}.png\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for project_name in apps_set:\n",
    "    try:\n",
    "        plot_ac_report_bar(project_name)\n",
    "    except:\n",
    "        print(f\"Failed to render graph for {project_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellBroadcastReceiver analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ck_cellbroadcastreceiver = ck_in_a_project(\"packages/apps/CellBroadcastReceiver\").groupby(\"file_path\").mean(numeric_only=True).reset_index()\n",
    "# df_ck_cellbroadcastreceiver = df_ck_cellbroadcastreceiver[[\"wmc\", \"file_path\"]]\n",
    "df_ck_cellbroadcastreceiver[\"file_path\"] = df_ck_cellbroadcastreceiver[\"file_path\"].astype(\"str\")\n",
    "# df_ck_cellbroadcastreceiver[\"wmc_sum\"] = df_ck_cellbroadcastreceiver[\"wmc\"].sum()\n",
    "# print(df_ck_cellbroadcastreceiver.dtypes)\n",
    "df_ck_cellbroadcastreceiver[\"path\"] = df_ck_cellbroadcastreceiver[\"file_path\"]\n",
    "df_files_cellbroadcastreceiver = files_in_a_project(\"packages/apps/CellBroadcastReceiver\")[[\"path\", \"loc\"]]\n",
    "df_files_cellbroadcastreceiver[\"path\"] = df_files_cellbroadcastreceiver[\"path\"].astype(str)\n",
    "df_ck_cellbroadcastreceiver.drop(columns=[\"loc\"], inplace=True) # drop loc, use from files instead.\n",
    "\n",
    "pd_merged = pd.merge(df_files_cellbroadcastreceiver, df_ck_cellbroadcastreceiver, how=\"left\", on=\"path\").dropna()\n",
    "df_ac_cellbroadcastreceiver = acs_in_a_project(\"packages/apps/CellBroadcastReceiver\")[[\"path\", \"ac_count\"]]\n",
    "\n",
    "pd_merged = pd.merge(pd_merged, df_ac_cellbroadcastreceiver, how=\"left\", on=\"path\")\n",
    "pd_merged.infer_objects(copy=False)\n",
    "pd_merged[\"ac_count\"] = pd_merged[\"ac_count\"].astype(float).fillna(0).astype(int)\n",
    "pd_merged[\"loc\"] = pd_merged[\"loc\"].astype(int)\n",
    "pd_merged[\"wmc\"] = pd_merged[\"wmc\"].astype(int)\n",
    "pd_merged.drop(columns=[\"file_path\"], inplace=True)\n",
    "pd_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_merged.corr(method=\"pearson\", numeric_only=True)[\"ac_count\"].sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
